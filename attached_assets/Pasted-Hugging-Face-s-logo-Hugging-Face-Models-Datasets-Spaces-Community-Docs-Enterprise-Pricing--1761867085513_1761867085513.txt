Hugging Face's logo
Hugging Face
Models
Datasets
Spaces
Community
Docs
Enterprise
Pricing


UncleBender69
/
test 
private
Model card
Files and versions
xet
Community
Settings
test
/
handler.py

UncleBender69's picture
UncleBender69
Update handler.py
f817e14
verified
16 days ago
raw

Copy download link
history
blame
edit
delete

5.82 kB
import os
import io
import base64
from typing import Any, Dict, List, Optional

import torch
from PIL import Image
from diffusers import (
    StableDiffusionXLPipeline,
    StableDiffusionPipeline,
    DPMSolverMultistepScheduler,
    EulerAncestralDiscreteScheduler,
    EulerDiscreteScheduler,
    DDIMScheduler,
    LMSDiscreteScheduler,
    PNDMScheduler,
)

class EndpointHandler:
    """
    Custom handler for single-file Stable Diffusion checkpoints.
    Features:
    - Auto-detect SDXL vs SD1.x/2.x via from_single_file
    - Text-to-image with parameters in JSON
    - Returns either JSON (base64) or raw JPEG bytes with proper Content-Type
      when payload includes: {"accept": "image/jpeg"} or {"headers": {"accept": "image/jpeg"}}
    """
    def __init__(self, path: str = ""):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.dtype = torch.float16 if self.device == "cuda" else torch.float32

        # Resolve checkpoint path
        ckpt_env = os.getenv("SAFETENSORS_FILENAME")
        if ckpt_env:
            ckpt_path = ckpt_env if os.path.isabs(ckpt_env) else os.path.join(path, ckpt_env)
        else:
            candidates = []
            for root, _, files in os.walk(path or "."):
                for f in files:
                    if f.endswith(".safetensors"):
                        candidates.append(os.path.join(root, f))
            if not candidates:
                raise RuntimeError("No .safetensors checkpoint found in repository.")
            ckpt_path = candidates[0]

        # Try SDXL first; fall back to SD 1.x/2.x
        self.is_sdxl = True
        try:
            self.pipe = StableDiffusionXLPipeline.from_single_file(
                ckpt_path,
                torch_dtype=self.dtype,
                use_safetensors=True,
                add_watermarker=False,
            )
        except Exception:
            self.is_sdxl = False
            self.pipe = StableDiffusionPipeline.from_single_file(
                ckpt_path,
                torch_dtype=self.dtype,
                use_safetensors=True,
            )

        # Light memory/perf tweaks
        if hasattr(self.pipe, "enable_attention_slicing"):
            self.pipe.enable_attention_slicing("max")
        if hasattr(self.pipe, "enable_vae_slicing"):
            self.pipe.enable_vae_slicing()
        if hasattr(self.pipe, "set_progress_bar_config"):
            self.pipe.set_progress_bar_config(disable=True)

        self.pipe.to(self.device)

        # Supported schedulers
        self.schedulers = {
            "euler_a": EulerAncestralDiscreteScheduler,
            "euler": EulerDiscreteScheduler,
            "ddim": DDIMScheduler,
            "lms": LMSDiscreteScheduler,
            "pndm": PNDMScheduler,
            "dpmpp_2m": DPMSolverMultistepScheduler,
        }

    def _set_scheduler(self, name: Optional[str]) -> None:
        if not name:
            return
        name = name.lower()
        if name in self.schedulers:
            cls = self.schedulers[name]
            self.pipe.scheduler = cls.from_config(self.pipe.scheduler.config)

    def __call__(self, data: Dict[str, Any]):
        # Allow either {"inputs": {...}} or flat dict
        payload = data.get("inputs", data)

        # Output negotiation: raw JPEG vs JSON
        accept = (data.get("accept")
                  or data.get("headers", {}).get("accept")
                  or payload.get("accept")
                  or "json").lower()

        prompt = payload.get("prompt", "")
        negative_prompt = payload.get("negative_prompt", None)

        width = int(payload.get("width", 1024 if self.is_sdxl else 512))
        height = int(payload.get("height", 1024 if self.is_sdxl else 512))
        steps = int(payload.get("num_inference_steps", 30))
        guidance = float(payload.get("guidance_scale", 6.5 if self.is_sdxl else 7.5))
        num_images = int(payload.get("num_images", 1))
        seed = payload.get("seed", None)
        scheduler_name = payload.get("scheduler", None)

        self._set_scheduler(scheduler_name)

        generator = None
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(int(seed))

        with torch.inference_mode():
            out = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                num_inference_steps=steps,
                guidance_scale=guidance,
                num_images_per_prompt=num_images,
                generator=generator,
            )

        images: List[Image.Image] = out.images

        # If user wants a directly viewable image in the Endpoint UI, return image/jpeg
        if accept in ("image/jpeg", "image/jpg", "binary", "jpeg"):
            img = images[0].convert("RGB")
            buf = io.BytesIO()
            img.save(buf, format="JPEG", quality=90, optimize=True)
            jpeg_bytes = buf.getvalue()
            # Return (bytes, headers) to set MIME for Inference Endpoints
            return jpeg_bytes, {"content-type": "image/jpeg"}

        # Default JSON response with base64 (compatible with API clients)
        results = []
        for img in images:
            buf = io.BytesIO()
            # Default to PNG for lossless JSON path
            img.save(buf, format="PNG")
            b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
            results.append({"b64_json": b64, "mime": "image/png"})

        return {
            "images": results,
            "pipeline": "sdxl" if self.is_sdxl else "sd15",
            "width": width,
            "height": height,
            "steps": steps,
            "guidance_scale": guidance,
            "scheduler": scheduler_name or "default",
        }

